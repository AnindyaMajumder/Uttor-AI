# ЁЯдЦ Uttor-AI

> An intelligent Bengali Q&A system powered by Retrieval-Augmented Generation (RAG), specifically designed for Higher Secondary Bangla.

## я┐╜ Table of Contents

- [тЬи Key Features](#-key-features)
- [ЁЯЪА Quick Start](#-quick-start)
- [ЁЯТм Quesion & Answer regarding the project](#-A-few-Q&-A-regarding-the-project)
- [ЁЯдФ Design Choices & Rationale](#-design-choices--rationale)
- [ЁЯУЪ API Documentation](#-api-documentation)
- [ЁЯПЧя╕П Project Structure](#я╕П-project-structure)

## тЬи Key Features

- ЁЯОп **Subject-Specific Expertise**: Focused on HSC Bangla 1st Paper content using **pytesseract** and **pdf2image** for document processing
- ЁЯза **Smart Processing**: Bengali text processing with **bnlp_toolkit** and **NLTK**
- ЁЯФН **Intelligent Retrieval**: Advanced RAG system with **Pinecone** vector database and **BAAI/bge-m3** embeddings for accurate context matching
- ЁЯМР **Multilingual Input**: Accepts questions in any language 
- ЁЯУЪ **Book-First Approach**: Prioritizes answers from provided pdf
- ЁЯОн **Teacher Persona**: Responds like a knowledgeable school teacher powered by **OpenAI GPT-4.1**
- тЪб **Fast API**: RESTful API built with **FastAPI** for easy integration

## ЁЯЪА Quick Start

### Prerequisites

- Python 3.10.11 (recommended)
- OpenAI API key
- Pinecone API key
- Tesseract OCR (for PDF text extraction)

### Installation

1. **Install Tesseract OCR**
   
   **On Ubuntu/Debian:**
   ```bash
   sudo apt update
   sudo apt install tesseract-ocr
   sudo apt install libtesseract-dev
   ```
   
   **On Windows:**
   - Download Tesseract installer from: https://github.com/UB-Mannheim/tesseract/wiki
   - Install and add Tesseract to your PATH environment variable

2. **Clone the repository**
   ```bash
   git clone https://github.com/AnindyaMajumder/Uttor-AI.git
   cd Uttor-AI
   ```

3. **Create a virtual environment**
   
   **Using venv (recommended):**
   ```bash
   python -m venv .venv
   ```
   or
   ```bash
   py -3.10 -m venv .venv
   ```
   
   **Activate virtual environment:**
   ```bash
   # On Linux/Mac:
   source .venv/bin/activate
   
   # On Windows (Command Prompt):
   .venv\Scripts\activate
   
   # On Windows (PowerShell):
   .venv\Scripts\Activate.ps1
   ```

4. **Install dependencies**
   1. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

5. **Set up environment variables**
   Create a `.env` file in the root directory:
   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   PINECONE_API_KEY=your_pinecone_api_key_here
   ```

6. **Run the application**
   ```bash
      uvicorn app:app --host 127.0.0.1 --port 8000
   ```

   The API will be available at `http://127.0.0.1:8000`

##  Sample Queries and Outputs

### Bengali Queries

**Query (Bengali):**
```
рж░ржмрзАржирзНржжрзНрж░ржирж╛рже ржарж╛ржХрзБрж░рзЗрж░ 'рж╕рзЛржирж╛рж░ рждрж░рзА' ржХржмрж┐рждрж╛рж░ ржорзВрж▓ ржмрж┐рж╖ржпрж╝ржмрж╕рзНрждрзБ ржХрзА?
```

**Response:**
```
рж░ржмрзАржирзНржжрзНрж░ржирж╛рже ржарж╛ржХрзБрж░рзЗрж░ 'рж╕рзЛржирж╛рж░ рждрж░рзА' ржХржмрж┐рждрж╛ржЯрж┐ ржорзВрж▓ржд ржХржмрж┐рж░ ржЬрзАржмржирзЗрж░ ржХрзНрж╖ржгрж╕рзНржерж╛ржпрж╝рж┐рждрзНржм ржУ рж╢рж┐рж▓рзНржкрзЗрж░ рж╕рзНржерж╛ржпрж╝рж┐рждрзНржмрзЗрж░ ржжрзНржмржирзНржжрзНржм ржирж┐ржпрж╝рзЗ рж░ржЪрж┐рждред ржХржмрж┐рждрж╛ржпрж╝ ржжрзЗржЦрж╛ ржпрж╛ржпрж╝ ржпрзЗ, ржХрзГрж╖ржХ рждрж╛рж░ рж╕рзЛржирж╛рж▓рж┐ ржзрж╛ржирзЗрж░ ржлрж╕рж▓ ржирж┐ржпрж╝рзЗ ржорж╛ржЭрж┐рж░ ржХрж╛ржЫрзЗ ржпрж╛ржпрж╝, ржХрж┐ржирзНрждрзБ ржорж╛ржЭрж┐ рж╢рзБржзрзБ ржлрж╕рж▓ ржирж┐ржпрж╝рзЗ ржпрж╛ржпрж╝, ржХрзГрж╖ржХржХрзЗ ржирж┐ржпрж╝рзЗ ржпрж╛ржпрж╝ ржирж╛ред ржПржЦрж╛ржирзЗ ржлрж╕рж▓ рж╣рж▓рзЛ ржХржмрж┐рж░ рж╕рзГрж╖рзНржЯрж┐ржХрж░рзНржо ржЖрж░ ржХрзГрж╖ржХ рж╣рж▓рзЛ ржХржмрж┐ ржирж┐ржЬрзЗред ржХржмрж┐рждрж╛рж░ ржорзВрж▓ ржмрж╛рж░рзНрждрж╛ рж╣рж▓рзЛ рж╢рж┐рж▓рзНржк ржЕржорж░, ржХрж┐ржирзНрждрзБ рж╢рж┐рж▓рзНржкрзА ржорж░ржгрж╢рзАрж▓ред
```

**Query (Bengali):**
```
'ржЖржорж╛рж░ ржкрже' ржкрзНрж░ржмржирзНржзрзЗ ржХрж╛ржЬрзА ржиржЬрж░рзБрж▓ ржЗрж╕рж▓рж╛ржо ржХрзА ржмрж╛рж░рзНрждрж╛ ржжрж┐ржпрж╝рзЗржЫрзЗржи?
```

**Response:**
```
'ржЖржорж╛рж░ ржкрже' ржкрзНрж░ржмржирзНржзрзЗ ржХрж╛ржЬрзА ржиржЬрж░рзБрж▓ ржЗрж╕рж▓рж╛ржо ржорж╛ржирзБрж╖рзЗрж░ ржмрзНржпржХрзНрждрж┐рждрзНржм ржУ рж╕рзНржмрж╛ржзрзАржирждрж╛рж░ ржХржерж╛ ржмрж▓рзЗржЫрзЗржиред рждрж┐ржирж┐ ржмрж▓рзЗржЫрзЗржи ржпрзЗ, ржкрзНрж░рждрзНржпрзЗржХ ржорж╛ржирзБрж╖рзЗрж░ ржирж┐ржЬрж╕рзНржм ржкрже ржЖржЫрзЗ ржПржмржВ рж╕рзЗ ржкржерзЗ ржЪрж▓рждрзЗ ржЧрзЗрж▓рзЗ ржХрж╛рж░ржУ ржЕржирзБрж╕рж░ржг ржХрж░рж╛рж░ ржкрзНрж░ржпрж╝рзЛржЬржи ржирзЗржЗред рждрж┐ржирж┐ ржзрж░рзНржорзАржпрж╝ ржЧрзЛржБржбрж╝рж╛ржорж┐, рж╕рж╛ржорж╛ржЬрж┐ржХ ржХрзБрж╕ржВрж╕рзНржХрж╛рж░ ржУ ржкрзНрж░ржерж╛ржЧржд ржмрж┐ржзрж┐-ржирж┐рж╖рзЗржзрзЗрж░ ржмрж┐рж░рзБржжрзНржзрзЗ ржкрзНрж░рждрж┐ржмрж╛ржж ржХрж░рзЗржЫрзЗржиред ржиржЬрж░рзБрж▓рзЗрж░ ржорждрзЗ, рж╕рждрзНржпрж┐ржХрж╛рж░рзЗрж░ ржорж╛ржирзБрж╖ рж╣рждрзЗ рж╣рж▓рзЗ ржирж┐ржЬрзЗрж░ ржмрж┐ржмрзЗржХ ржУ ржпрзБржХрзНрждрж┐ ржжрж┐ржпрж╝рзЗ ржкрже ржмрзЗржЫрзЗ ржирж┐рждрзЗ рж╣ржмрзЗред
```

### English Queries (Bengali Responses)

**Query (English):**
```
What is the theme of Rabindranath Tagore's "Gitanjali"?
```

**Response:**
```
рж░ржмрзАржирзНржжрзНрж░ржирж╛рже ржарж╛ржХрзБрж░рзЗрж░ 'ржЧрзАрждрж╛ржЮрзНржЬрж▓рж┐' ржХрж╛ржмрзНржпржЧрзНрж░ржирзНржерзЗрж░ ржорзВрж▓ ржмрж┐рж╖ржпрж╝ржмрж╕рзНрждрзБ рж╣рж▓рзЛ ржнржХрзНрждрж┐ ржУ ржЖржзрзНржпрж╛рждрзНржорж┐ржХрждрж╛ред ржПржЗ ржХрж╛ржмрзНржпржЧрзНрж░ржирзНржерзЗ ржХржмрж┐ ржИрж╢рзНржмрж░рзЗрж░ ржкрзНрж░рждрж┐ рждрж╛ржБрж░ ржЧржнрзАрж░ ржнрж╛рж▓рзЛржмрж╛рж╕рж╛ ржУ ржирж┐ржмрзЗржжржирзЗрж░ ржХржерж╛ ржмрзНржпржХрзНржд ржХрж░рзЗржЫрзЗржиред ржЧрзАрждрж╛ржЮрзНржЬрж▓рж┐рж░ ржХржмрж┐рждрж╛ржЧрзБрж▓рзЛрждрзЗ ржорж╛ржирзБрж╖ ржУ рж╕рзНрж░рж╖рзНржЯрж╛рж░ ржоржзрзНржпржХрж╛рж░ рж╕ржорзНржкрж░рзНржХ, ржЬрзАржмржирзЗрж░ ржЕрж░рзНрже, ржорзГрждрзНржпрзБржЪрзЗрждржирж╛ ржПржмржВ ржкрж░ржоржкрзНрж░рзЗржорзЗрж░ ржмрж┐рж╖ржпрж╝ржЧрзБрж▓рзЛ рж╕рзНржерж╛ржи ржкрзЗржпрж╝рзЗржЫрзЗред ржПржЗ ржХрж╛ржмрзНржпржЧрзНрж░ржирзНржерзЗрж░ ржЬржирзНржп рж░ржмрзАржирзНржжрзНрж░ржирж╛рже рззрзпрззрзй рж╕рж╛рж▓рзЗ ржирзЛржмрзЗрж▓ ржкрзБрж░рж╕рзНржХрж╛рж░ рж▓рж╛ржн ржХрж░рзЗржиред
```

## ЁЯдФ A few Q&A regarding the project

#### 1. What method or library did you use to extract the text, and why? Did you face any formatting challenges with the PDF content?
I employed pdf2image to convert each PDF page into a highтАСresolution image, followed by pytesseract with the Bengali trained data to perform optical character recognition. This approach was necessary because, despite the fonts being selectable, they were not mapped to Unicode code points. Preprocessing stepsтАФsuch as binarisation and noise reductionтАФwere applied to improve the clarity of the scanned text and thereby enhance recognition accuracy

#### 2. What chunking strategy did you choose (e.g. paragraph-based, sentence-based, character limit)? Why do you think it works well for semantic retrieval?
I opted for a sentenceтАСbased segmentation method. Firstly, the raw text was cleaned using the bnlp toolkit to remove artefacts and standardise punctuation. Subsequently, I split on sentence boundaries detected by the semantic splitter using OPENAI's ```text-embedding-3-large``` with breakpoint thresold amount as `0.8`, rather than imposing arbitrary character limits. This yields selfтАСcontained, semantically coherent fragments that are well suited to vectorтАСbased similarity search. For every page it will generate numerous embeddings based on the context. I excluded pages composed primarily of MCQs, since these often lack explanatory context and could degrade retrieval precision.

#### 3. What embedding model did you use? Why did you choose it? How does it capture the meaning of the text?
For vectorisation I selected the ```BGEтАСm3``` embedding model, owing to its robust support for Bangla script and its capacity to process extended passages (up to 8000 tokens). The model generates dense numerical representations that capture the semantic relationships between words and phrases, facilitating the retrieval of passages that best match a given query.

#### 4. How are you comparing the query with your stored chunks? Why did you choose this similarity method and storage setup?
Queries and document fragments are both encoded with the ```BGEтАСm3``` model, after which cosine similarity is computed between the query vector and each fragment vector. All vectors are stored in a Pinecone index for efficient approximate nearestтАСneighbour search using cosine similarity. 

#### 5. How do you ensure that the question and the document chunks are compared meaningfully? What would happen if the query is vague or missing context?
By using the same embedding model for queries and document fragments, the system ensures that both are represented in a common semantic space. A similarity threshold is applied: if the highest cosine score falls below a predetermined cutoff, the system informs the user that it cannot locate a relevant passage and suggests rephrasing or providing additional detail.

#### 6. Do the results seem relevant? If not, what might improve them (e.g. better chunking, better embedding model, larger document)?
Overall, the retrieved passages align pretty much well with user queries. Introducing postтАСOCR cleaning such as common misrecognition corrections for specific Bangla characters to reduce OCR errors. Also, labeling a small subset of queryтАУpassage pairs manually and fineтАСtune a crossтАСencoder reranker, thereby improving precision on top results.

## ЁЯУЪ API Documentation

### Base URL
```
http://127.0.0.1:8000
```

### Endpoints

#### POST `/ask`

**Request Body:**
```json
{
  "query": "string"
}
```

**Response:**
```json
{
  "messages": [
    {
      "role": "system",
      "content": "System prompt..."
    },
    {
      "role": "user", 
      "content": "User question ..."
    },
    {
      "role": "assistant",
      "content": "AI response in Bengali ..."
    }
  ]
}
```

## ЁЯПЧя╕П Project Structure

```
Uttor-AI/
тФЬтФАтФА app.py                 # FastAPI application entry point
тФЬтФАтФА requirements.txt       # Python dependencies
тФЬтФАтФА README.md             # Project documentation
тФЬтФАтФА LICENSE               # Project license
тФФтФАтФА rag/                  # RAG implementation
    тФЬтФАтФА chain.py          # Main RAG chain logic
    тФЬтФАтФА vectorstore.py    # Vector store operations
    тФЬтФАтФА core/             # Core RAG components
    тФВ   тФЬтФАтФА embeddings.py # Embedding models
    тФВ   тФЬтФАтФА model.py      # Language model setup
    тФВ   тФЬтФАтФА retriever.py  # Document retrieval logic
    тФВ   тФФтФАтФА setup.py      # Configuration setup
    тФЬтФАтФА data/             # Educational content
    тФВ   тФФтФАтФА HSC26-Bangla1st-Paper.pdf
    тФФтФАтФА preprocessing/    # Data processing
        тФЬтФАтФА clean_text.py # Text cleaning utilities
        тФЬтФАтФА loader.py     # Document loaders
        тФФтФАтФА splitter.py   # Text chunking
```